<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 4 Bag of Words: TF-IDF | NLP Galore</title>
<meta name="author" content="Various Sources">
<meta name="generator" content="bookdown 0.28 with bs4_book()">
<meta property="og:title" content="Chapter 4 Bag of Words: TF-IDF | NLP Galore">
<meta property="og:type" content="book">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 4 Bag of Words: TF-IDF | NLP Galore">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.0/transition.js"></script><script src="libs/bs3compat-0.4.0/tabs.js"></script><script src="libs/bs3compat-0.4.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<meta name="description" content="4.1 Bag of Words A bag of words is a representation of text that describes the occurrence of words within a document. We just keep track of word counts and disregard the grammatical details and...">
<meta property="og:description" content="4.1 Bag of Words A bag of words is a representation of text that describes the occurrence of words within a document. We just keep track of word counts and disregard the grammatical details and...">
<meta name="twitter:description" content="4.1 Bag of Words A bag of words is a representation of text that describes the occurrence of words within a document. We just keep track of word counts and disregard the grammatical details and...">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">NLP Galore</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Introduction</a></li>
<li class="book-part">BASICS OF NLP</li>
<li><a class="" href="dictionary-based-methods.html"><span class="header-section-number">2</span> Dictionary-Based Methods</a></li>
<li><a class="" href="regression-based-methods.html"><span class="header-section-number">3</span> Regression-Based Methods</a></li>
<li><a class="active" href="bag-of-words-tf-idf.html"><span class="header-section-number">4</span> Bag of Words: TF-IDF</a></li>
<li><a class="" href="basic-word-embeddings-word2vec-glove.html"><span class="header-section-number">5</span> Basic Word Embeddings: Word2Vec &amp; Glove</a></li>
<li><a class="" href="topic-modelling-lda.html"><span class="header-section-number">6</span> Topic Modelling: LDA</a></li>
<li><a class="" href="sequence-models-rnns-and-lstms.html"><span class="header-section-number">7</span> Sequence Models: RNNs and LSTMs</a></li>
<li><a class="" href="attention-models-and-transformers.html"><span class="header-section-number">8</span> Attention Models and Transformers</a></li>
<li><a class="" href="pretrained-models-and-fine-tuning.html"><span class="header-section-number">9</span> Pretrained Models and Fine-Tuning</a></li>
<li><a class="" href="other-useful-methods-for-textual-analysis.html"><span class="header-section-number">10</span> Other Useful Methods for Textual Analysis</a></li>
<li class="book-part">APPLICATIONS IN ECON/FINANCE</li>
<li><a class="" href="sentiment-analysis.html"><span class="header-section-number">11</span> Sentiment Analysis</a></li>
<li class="book-part">CODE SNIPPETS</li>
<li><a class="" href="data-scraping.html"><span class="header-section-number">12</span> Data Scraping</a></li>
<li><a class="" href="data-cleaning.html"><span class="header-section-number">13</span> Data Cleaning</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="bag-of-words-tf-idf" class="section level1" number="4">
<h1>
<span class="header-section-number">4</span> Bag of Words: TF-IDF<a class="anchor" aria-label="anchor" href="#bag-of-words-tf-idf"><i class="fas fa-link"></i></a>
</h1>
<div id="bag-of-words" class="section level2" number="4.1">
<h2>
<span class="header-section-number">4.1</span> Bag of Words<a class="anchor" aria-label="anchor" href="#bag-of-words"><i class="fas fa-link"></i></a>
</h2>
<p>A bag of words is a representation of text that describes the occurrence of words within a document. We just keep track of word counts and disregard the grammatical details and the word order. It is called a “bag” of words because any information about the order or structure of words in the document is discarded. The model is only concerned with whether known words occur in the document, not where in the document.</p>
<div id="bag-of-n-grams" class="section level3" number="4.1.1">
<h3>
<span class="header-section-number">4.1.1</span> Bag of N-Grams<a class="anchor" aria-label="anchor" href="#bag-of-n-grams"><i class="fas fa-link"></i></a>
</h3>
<div id="the-idea" class="section level4" number="4.1.1.1">
<h4>
<span class="header-section-number">4.1.1.1</span> The Idea<a class="anchor" aria-label="anchor" href="#the-idea"><i class="fas fa-link"></i></a>
</h4>
<p>In general, bigrams make tokens more understandable. Suppose we have two sentences:</p>
<ul>
<li>Sentence 1: “This is a good job. I will not miss it for anything”</li>
<li>Sentence 2: ”This is not good at all”</li>
</ul>
<p>and let us take the vocabulary of 5 words only: “good”, “job”, “miss”, “not”, and “all.”</p>
<p>In this case, the respective vectors for these sentences are:</p>
<ul>
<li>Sentence 1: “This is a good job. I will not miss it for anything” = <strong>[1,1,1,1,0]</strong>
</li>
<li>Sentence 2: ”This is not good at all” = <strong>[1,0,0,1,1]</strong>
</li>
</ul>
<p>Sentence 2 is a negative sentence, yet this distinction is not reflected in the vectors.</p>
<p>Now, suppose instead we use bigrams, in which case Sentence 2 can be broken into: “This is”, “is not”, “not good”, “good at”, and “at all.” In this case, the model can differentiate between sentence 1 and sentence 2.</p>
</div>
<div id="pre-processing-to-reduce-feature-space" class="section level4" number="4.1.1.2">
<h4>
<span class="header-section-number">4.1.1.2</span> Pre-Processing to Reduce Feature Space<a class="anchor" aria-label="anchor" href="#pre-processing-to-reduce-feature-space"><i class="fas fa-link"></i></a>
</h4>
<p>Using N-grams increases the feature space, so a1. few techniques are used to reduce it:</p>
<ul>
<li>Removing stopwords such as a, the, and, it, is, etc.</li>
<li>Stemming: This is the process of reducing a word to its word stem. For example, words like swimmer, swimming, swim, will be mapped to one-word swim.</li>
<li>Chunking and Parts-of-speech tagging: One can use these techniques to find meaningful words in a sentence and use them as the feature vector</li>
</ul>
</div>
</div>
</div>
<div id="tf-idf" class="section level2" number="4.2">
<h2>
<span class="header-section-number">4.2</span> TF-IDF<a class="anchor" aria-label="anchor" href="#tf-idf"><i class="fas fa-link"></i></a>
</h2>
<p>TF-IDF is intended to reflect how relevant a term is in a given document. It makes rare words more prominent and effectively ignores common words. Therefore, unlike bag-of-words, it creates a normalized count where each word count is divided by the number of documents this word appears in.</p>
<p>It is computed by multiplying two different metrics:</p>
<ul>
<li><p><strong>Term Frequency (TF)</strong> of a word <span class="math inline">\(t\)</span> in document <span class="math inline">\(d\)</span> is given as
<span class="math display">\[
tf(t,d) = \frac{f_{t,d}}{\sum_{t'\in d} f_{t',d}}
\]</span>
where <span class="math inline">\(f_{t,d}\)</span> is the raw count of a term in a document. The denominator is the total number of terms in document <span class="math inline">\(d\)</span>.</p></li>
<li><p><strong>Inverse Document Frequency (IDF)</strong> of a word <span class="math inline">\(t\)</span> in a set of documents <span class="math inline">\(D\)</span> is given as
<span class="math display">\[
idf(t,D) = \log\frac{N}{|\{d\in D:t\in d\}|}
\]</span>
where <span class="math inline">\(N=|D|\)</span> and the denominator is the number of documents where the term <span class="math inline">\(t\)</span> appears.</p></li>
</ul>
<p>Then TF-IDF is then calculated as:
<span class="math display">\[
tfidf(t,d,D) = tf(t,d)\times idf(t,D)
\]</span>
A high weight in TF-IDF is reached by a high term frequency (in the given document) and a low document frequency of the term in the whole collection of documents</p>
</div>
<div id="limitations-of-bag-of-words" class="section level2" number="4.3">
<h2>
<span class="header-section-number">4.3</span> Limitations of Bag of Words<a class="anchor" aria-label="anchor" href="#limitations-of-bag-of-words"><i class="fas fa-link"></i></a>
</h2>
<p>Although Bag-of-Words is quite efficient and easy to implement, there still are disadvantages.</p>
<ol style="list-style-type: decimal">
<li><p><strong>It suffers from the curse of dimensionality</strong> as the total dimension is generally the vocabulary size. Therefore, Its vocabulary needs to be designed carefully to manage the size. At the same time, bag of words also often leads to sparse vectors, which require more memory and computational resources.</p></li>
<li><p><strong>The model ignores the location information of the word.</strong> The location information is a piece of very important information in the text. For example “today is off” and “Is today off”, have the exact same vector representation in the BoW model.</p></li>
<li><p><strong>The model ignores the semantics of the word.</strong> For example, words ‘soccer’ and ‘football’ are often used in the same context. However, the vectors corresponding to these words are quite different in the bag of words model.</p></li>
<li><p><strong>The range of vocabulary is a big issue faced by the Bag-of-Words model.</strong> If the model comes across a new word, it ends up ignoring the word.</p></li>
</ol>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="regression-based-methods.html"><span class="header-section-number">3</span> Regression-Based Methods</a></div>
<div class="next"><a href="basic-word-embeddings-word2vec-glove.html"><span class="header-section-number">5</span> Basic Word Embeddings: Word2Vec &amp; Glove</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#bag-of-words-tf-idf"><span class="header-section-number">4</span> Bag of Words: TF-IDF</a></li>
<li>
<a class="nav-link" href="#bag-of-words"><span class="header-section-number">4.1</span> Bag of Words</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#bag-of-n-grams"><span class="header-section-number">4.1.1</span> Bag of N-Grams</a></li></ul>
</li>
<li><a class="nav-link" href="#tf-idf"><span class="header-section-number">4.2</span> TF-IDF</a></li>
<li><a class="nav-link" href="#limitations-of-bag-of-words"><span class="header-section-number">4.3</span> Limitations of Bag of Words</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>NLP Galore</strong>" was written by Various Sources. It was last built on 2022-08-28.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
