introduction
dictionary-based-methods
a-stylized-guide
often-used-dictionaries
loughran-mcdonald-lm-dictionary
regression-based-methods
challenges-of-having-text-as-the-dependent-variable
distributed-multinomial-regressions-dmr
extension-hurdle-dmr-hdmr
application-1-using-text-to-measure-traditionally-difficult-to-quantify-concepts
application-2-using-text-data-to-forecast-nowcast-and-backcast-hard-data
bag-of-words-tf-idf
bag-of-words
bag-of-n-grams
the-idea
pre-processing-to-reduce-feature-space
tf-idf
limitations-of-bag-of-words
basic-word-embeddings-word2vec-glove
overview
svd-based-methods
limitations
iteration-based-methods
word2vec
method-1-cbow
method-2-skip-gram
implementation-details
best-of-both-worlds-glove
topic-modelling-lda
notation-and-terminology
models-that-preceded-the-lda
latent-semantic-models-lsa
probabilistic-latent-semantic-models-plsa
latent-dirichlet-allocation-lda
challenges-of-working-with-lda
intractable-likelihood-and-estimation
packages-for-implementing-the-standard-lda
extensions-to-the-standard-lda
dynamic-lda
supervised-lda
sequence-models-rnns-and-lstms
sequence-models
n-gram-language-models
rnn-neural-networks-with-memory
basic-rnn-architecture
training-rnns
vanishing-and-exploding-gradients
applications
lstm
basic-lstm-architecture
variations
other-extensions
bidirectional-rnns
multi-layer-rnns
attention-models-and-transformers
attention
basic-idea
steps-for-computing-attention
self-attention
transformers
overview-1
step-1.-embedding
step-2.-self-attention-in-encoders
step-3.-self-attention-in-decoders
step-4.-encoder-decoder-attention-in-decoders
references
pretrained-models-and-fine-tuning
bert
gpt
other-useful-methods-for-textual-analysis
convolutional-neural-networks-cnns
hidden-markov-models-hmms
sentiment-analysis
data-scraping
data-cleaning
word-tokenization
implementing-tokenization
n-grams
techniques-for-normalizing-the-vocabulary
